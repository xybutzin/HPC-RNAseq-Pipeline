# HPC RNA-seq Analysis Pipeline
This is an automated RNA-seq analysis pipeline designed to process paired-end FASTQ files for prokaryotic genomes. The pipeline is optimized for use on High-Performance Computing (HPC) environment and utiliszes the Slurm scheduler to enable parallel processing of multiple sequence files simultaneously.

The pipeline operates in two primary steps:
1. Preprocessing and Alignment: It performs quality control(FastQC), alignment (Bowtie2), and sorting/indexing (Samtools) for each sample pair. 
2. Feature Counting: After alignment, it runs feature counting (using featureCounts) across all samples, producing a consolidated text file containing count data for various genomic features. 

This script processes raw sequencing data in fastq or fastq.gz format, aligns it to a reference genome, and outputs counts for features such as coding sequences (CDS), rRNA, pseudogenes or other annotations specified in the provided genome annotation file.

## Features
- Processes raw sequencing data in FASTQ or FASTQ.GZ format
- Outputs quality reports, aligned reads (SAM/BAM), and sorted BAM files.
- Produces a consolidated text file containing featur counts of all input samples
- Compatible with Slurm HPC clusters for efficient, parallelized execution

#e Prerequites
The follwoing software tools are required:
- FastQC_test (v0.12.1 or later)
- Bowtie (v2.5.2 or later)
- Samtools (v1.19 or later)
- Subread (featureCounts)


## Usage
### Input
1. **Pair-end FASTQ files**: 
    - Input sequencing data must be in paired-end FASTQ format.
    - Naming convention: Use `_R1` and `_R2` in filenames to distinguish forward and reverse reads.
    - Files can be compressed (`fasta.gz`) or uncompressed (`.fastq`).

2. **Reference genome**: 
    - Pre-build Bowtie2 genome index files (`.bt2`) are required for alignment.
    - The pipeline includes two reference genome index sets:
        - **E.coli**: A commonly used *E. coli* strain for lab studies.
        - **E.coli_CFP**: *E.coli* MG1655 containing the pCFP-LAA-Km plasmid 
    - Ensure the appropriate genome index is specified in the script for alignment.

3. **Genome annotation file**: 
    - A .gff3 file is requried for feature counting, providing gene annotations. 
    - Two annotation files are included in the pipeline: 
        - **ecoli.gff3**: E.coli MG1655 (ecoli.gff3)
        - **ecoli-CFP.gff3**: E.coli MG1655 with pCFP-LAA-Km plasmid.
    - The corresponding annotation file must match the selected reference genome.

#### Note
Ensure all input files are stored in their appropriate subdirectories within the pipeline directory:
- Genome indices in `genome/index_genome/`
- Annotation files in `genome/reference_genome/`
- Input FASTQ files in `/data/`.

### Running the Script
1. Change directory to the scripts folder.
```bash
cd RNAseq-Pipeline/scripts
```
2. Submit the alignment script to a Slurm HPC cluster.
```bash
sh rnaseq_analysis_on_allfiles.sh
```
3. After all the jobs are done in step 2, run feature counting
```bash
sbatch fCount_on_allfiles.sh
```

### Output
- **Quality Reports**: Generated by FastQC, saved in `results/fastqc/`.
- **Algined Reads**: These are intermediate and processed files from the alignment step, saved in `results/bowtie2/`.
    - SAM files: Alignment files generated by Bowtie2.
    - BAM files: Compressed alignment files converted from SAM.
    - Sorted BAM files: BAM files sorted by genomic coordinates.
- **Feature Counts**:
    - Count files summarizing reads mapped to various genome features, saved in `results/featureCounts/`.
        - **CDS counts**: Counts for coding sequences.
        - **rRNA counts**: Reads mapped to ribosomal RNA regions.
        - **Pseudogene counts**: Reads mapped to pseudogenes.
        - **gene counts**: Total reads mapped to genes.

## Directory Structure

Below is the structure of the RNA-seq pipeline directory, hightlighting the key folders and files:
```plaintext
RNAseq-Pipeline/
├── data                           # Input FASTQ files
│   ├── C1_sub_R1.fastq.gz
│   ├── C1_sub_R2.fastq.gz
│   ├── C2_sub_R1.fastq.gz
│   ├── C2_sub_R2.fastq.gz
│   ├── C3_sub_R1.fastq.gz
│   └── C3_sub_R2.fastq.gz
├── genome                          # Reference genome and annotation files
│   ├── index_genome                # Pre-built Bowtie2 index files
│   │   ├── ecoli_mg1655            # E. coli MG1655 index  
│   │   │   ├── ecoli.1.bt2 
│   │   │   ├── ecoli.2.bt2
│   │   │   ├── ecoli.3.bt2
│   │   │   ├── ecoli.4.bt2
│   │   │   ├── ecoli.rev.1.bt2
│   │   │   └── ecoli.rev.2.bt2
│   │   └── listed_genome            # E.coli pCFP-LAA-Km index
│   │       ├── ecoli_CFP.1.bt2
│   │       ├── ecoli_CFP.2.bt2
│   │       ├── ecoli_CFP.3.bt2
│   │       ├── ecoli_CFP.4.bt2
│   │       ├── ecoli_CFP.rev.1.bt2
│   │       └── ecoli_CFP.rev.2.bt2
│   └── reference_genome              # Reference genome and annotation files
│       ├── ecoli-CFP.fasta
│       ├── ecoli-CFP.fasta.fai
│       ├── ecoli-CFP.gff3
│       ├── ecoli.fasta
│       ├── ecoli.fasta.fai
│       └── ecoli.gff3
├── README.md
├── results
    ├── fastqc/
    ├── bowtie2/
    └── featureCounts/
└── scripts
    ├── fCount_on_allfiles.sh
    ├── rnaseq_analysis_on_allfiles.sh
    ├── rnaseq_analysis_on_input_file.sh
    └── rnaseq_analysis_singlestep.sh

```
### Notes:
- Adjust the directory paths in the script to match your setup, especially if running on different systems.
- Ensure the input files (FASTQ, genomic indices, and annotation files are correctly placed in their respctive folders before starting the pipeline.

## Example
Use the toy dataset in the `data/` directory for test run.
- C1_sub_R1.fastq.gz
- C1_sub_R2.fastq.gz
- C2_sub_R1.fastq.gz
- C2_sub_R2.fastq.gz
- C3_sub_R1.fastq.gz
- C3_sub_R2.fastq.gz

Run the script:
```bash
cd RNAseq-Pipeline/scripts
sh rnaseq_analysis_on_allfiles.sh
sbatch fCount_on_allfiles.sh
```

### Notes
- Ensure sufficient storage and memory resources on your HPC cluster.
- Modify the script to adjust the number of cores (--cpus-per-task, -c), memory allocation (--mem) and time (-t) based on your dataset size.
- For large datasets, it's recommended to split jobs for optimal performance.

## License
This pipeline is distributed under the MIT license.